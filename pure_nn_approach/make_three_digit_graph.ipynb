{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### importing from other files and defining constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mns_dataloaders import two_concat_biased,two_concat,three_channels,five_channels,five_concat,four_gathered\n",
    "from mns_models import five_concat_Net,two_concat_Net,three_channels_Net,five_channels_Net,four_gathered_Net\n",
    "import torch\n",
    "\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### defining train and test functions for different tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            # print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    return correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_two_concat(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)# Compute prediction error\n",
    "        pred = model(X)\n",
    "        # loss = loss_fn(pred[:,:10], y[:,0])+loss_fn(pred[:,10:20], y[:,1])+loss_fn(pred[:,20:30], y[:,2])+loss_fn(pred[:,30:], y[:,3])\n",
    "        loss = loss_fn(pred[:,30:], y[:,3]) # replace by this to learn just from last digit\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            # print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "def test_two_concat(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred[:,-10:], y[:,-1]).item()\n",
    "            correct += (pred[:,-10:].argmax(1) == y[:,-1]).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    return correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train the networks and compute accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_array = [[] for i in range(3)]\n",
    "epochs = 100\n",
    "for task in range(3):\n",
    "    match task:\n",
    "        case 0:            \n",
    "            train_dataloader,test_dataloader = three_channels()\n",
    "            model = three_channels_Net().to(device)\n",
    "        case 1:            \n",
    "            train_dataloader,test_dataloader = two_concat()\n",
    "            model = two_concat_Net().to(device)\n",
    "        case 2:            \n",
    "            train_dataloader,test_dataloader = two_concat_biased()\n",
    "            model = two_concat_Net().to(device)\n",
    "        \n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "    if task ==0:\n",
    "        for t in range(epochs):\n",
    "            print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "            train(train_dataloader, model, loss_fn, optimizer)\n",
    "            accuracy = test(test_dataloader, model, loss_fn)\n",
    "            accuracy_array[task]+=[accuracy]\n",
    "        print(\"Done!\")\n",
    "    else:\n",
    "        for t in range(epochs):\n",
    "            print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "            train_two_concat(train_dataloader, model, loss_fn, optimizer)\n",
    "            accuracy = test_two_concat(test_dataloader, model, loss_fn)\n",
    "            accuracy_array[task]+=[accuracy]\n",
    "        print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### implement graph for three digit task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "x = list(range(len(accuracy_array[0])))\n",
    "y1 = accuracy_array[0]\n",
    "y2 = accuracy_array[1]\n",
    "y3 = accuracy_array[2]\n",
    "\n",
    "plt.plot(x, y1,label = \"three channels\")\n",
    "plt.plot(x, y2,label = \"two concat\")\n",
    "plt.plot(x, y3,label = \"two concat biased\")\n",
    "\n",
    "plt.xlabel(\"epoch number\")\n",
    "plt.ylabel(\"Accuracy (on 0-1 scale)\")\n",
    "plt.title('accuracy of across epochs (each train epoch has 100000 images)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
