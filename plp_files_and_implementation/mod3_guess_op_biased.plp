#python
import torch
import torchvision
import random

NUM_RANGE = (0,9)

# Digit classification network definition.
class Net(torch.nn.Module):
  def __init__(self):
    super().__init__()
    self.encoder = torch.nn.Sequential(
      torch.nn.Conv2d(1, 6, 5),
      torch.nn.MaxPool2d(2, 2),
      torch.nn.ReLU(True),
      torch.nn.Conv2d(6, 16, 5),
      torch.nn.MaxPool2d(2, 2),
      torch.nn.ReLU(True)
    )
    self.classifier = torch.nn.Sequential(
      torch.nn.Linear(16 * 4 * 4, 120),
      torch.nn.ReLU(),
      torch.nn.Linear(120, 84),
      torch.nn.ReLU(),
      torch.nn.Linear(84, 10),
      torch.nn.Softmax(1)
    )

  def forward(self, x):
    with open("debug.csv",'w',newline = '') as csvfile:
      csvwriter = csv.writer(csvfile,)
      csvwriter.writerow( [torch.cat([training_data[i][0]for i in range(len(training_data))]).shape]) 
    x = self.encoder(x)
    x = x.view(-1, 16 * 4 * 4)
    x = self.classifier(x)
    return x

# Return an instance of Net.
def digit_net(): return Net()
# Download training data from open datasets.
training_data_atoms = torchvision.datasets.MNIST(
    root="data",
    train=True,
    download=True,
    transform=torchvision.transforms.ToTensor(),
)

# Download test data from open datasets.
test_data_atoms = torchvision.datasets.MNIST(
    root="data",
    train=False,
    download=True,
    transform=torchvision.transforms.ToTensor(),
)
def generate_mod_set(operation):
        # input between 0-2
    if operation=="sum":
        tot = random.choice([0,1,2])
        n1 = random.choice([0,1,2])
        n2 = random.choice([0,1,2])
        n3 = random.choice([0,1,2])
        return (n1,(tot-n1)%3,n2,(tot-n2)%3,n3,(tot-n3)%3)
    elif operation == "dif":
        dif= random.choice([0,1,2])
        n1 = random.choice([0,1,2])
        n2 = random.choice([0,1,2])
        n3 = random.choice([0,1,2])
        return (n1,(n1-dif)%3,n2,(n2-dif)%3,n3,(n3-dif)%3)
    print("operation invalid")
    return None

test_digits= [[] for i in range(10)]
for img, label in test_data_atoms:
    test_digits[label]+=img.float().reshape(1, 28, 28)/255
train_digits= [[] for i in range(10)]
for img, label in training_data_atoms:
    train_digits[label]+=img.float().reshape(1, 28, 28)/255
    
def generate_train_data_point(numbers):
    data_point = [random.choice(train_digits[numbers[i]])[None,:,:] for i in range(5)]
    return data_point+[numbers[5]]

def generate_test_data_point(numbers):
    data_point = [random.choice(test_digits[numbers[i]])[None,:,:] for i in range(5)]
    return data_point+[numbers[5]]


training_data=[]
for i in range(10):
    operation = "sum"
    num = generate_mod_set(operation)
    training_data += [generate_train_data_point(num)+[operation]]

test_data=[]
for i in range(1):
    operation = random.choice(["sum","dif"])
    num = generate_mod_set(operation)
    test_data += [generate_test_data_point(num)+[operation]]


# MNIST images for the train set.
def mnist_images_train(num):
    return torch.cat([training_data[i][int(num)]for i in range(len(training_data))])[:,None,:,:]
# MNIST images for the test set.
def mnist_images_test(num): 
    # currently num is passed as float
    return torch.cat([test_data[i][int(num)] for i in range(len(test_data))])[:,None,:,:]
# Observed atoms for training.
def mnist_labels_train():
    # We join the two halves (top and bottom) of MNIST and join them together to get
    # two digits side by side. The labels are atoms encoding the sum of the two digits.
    labels = [(training_data[i][-2], training_data[i][-1]) for i in range(len(training_data))]
    return [[f"last_num({num})",f"equal("+ op +")"] for num,op in labels]

# keep labels for test data
import csv
def note_label_for_test(test_data):
  with open("operation_label.csv",'w',newline = '') as csvfile:
    csvwriter = csv.writer(csvfile)
    for i in range(len(test_data)):
      csvwriter.writerow([test_data[i][-2],test_data[i][-1]]) #last num, operation
note_label_for_test(test_data)

#end.

% Data of the first digit.
input(0) ~ test(@mnist_images_test(0)), train(@mnist_images_train(0)).
% Data of the second digit.
input(1) ~ test(@mnist_images_test(1)), train(@mnist_images_train(1)).
% Data of the third digit.
input(2) ~ test(@mnist_images_test(2)), train(@mnist_images_train(2)).
% Data of the fourth digit.
input(3) ~ test(@mnist_images_test(3)), train(@mnist_images_train(3)).
% Data of the fifth digit.
input(4) ~ test(@mnist_images_test(4)), train(@mnist_images_train(4)).

% Neural annotated disjunction over each digit from 0 to 9; use Adam as optimizer
% and a learning rate of 0.001.
?::digit(X, {0..9}) as @digit_net with optim = "Adam", lr = 0.001 :- input(X).
% The sum.

sum1(X) :- digit(0, A), digit(1, B), X = A+B.
sum2(Y) :- digit(2, A), digit(3, B), Y = A+B.
equal(sum) :- sum1(X),sum2(Y),X\3=Y\3.

dif1(X) :- digit(0, A), digit(1, B), X = A-B.
dif2(Y) :- digit(2, A), digit(3, B), Y = A-B.
equal(dif):- dif1(X),dif2(Y),X\3=Y\3.


sat :- equal(sum).
sat :- equal(dif).
last_num(L):- equal(sum),sum1(X),digit(4,C),S=X-C,L=S\3.
last_num(L):- equal(dif),dif1(X),digit(4,C),S=C-X,L=S\3.

% Learn the parameters of the program from the "sum(X)" atoms.
#learn @mnist_labels_train, lr = 1., niters = 5, alg = "lagrange", batch = 50.
#semantics maxent.
% Ask for the probability of all groundings of last_num(L).
#query last_num(L)|sat.
