#python
import torch
import torchvision
import random

NUM_RANGE = (0,9)

# Digit classification network definition.
class Net(torch.nn.Module):
  def __init__(self):
    super().__init__()
    self.encoder = torch.nn.Sequential(
      torch.nn.Conv2d(1, 6, 5),
      torch.nn.MaxPool2d(2, 2),
      torch.nn.ReLU(True),
      torch.nn.Conv2d(6, 16, 5),
      torch.nn.MaxPool2d(2, 2),
      torch.nn.ReLU(True)
    )
    self.classifier = torch.nn.Sequential(
      torch.nn.Linear(16 * 4 * 4, 120),
      torch.nn.ReLU(),
      torch.nn.Linear(120, 84),
      torch.nn.ReLU(),
      torch.nn.Linear(84, 10),
      torch.nn.Softmax(1)
    )

  def forward(self, x):
    with open("debug.csv",'w',newline = '') as csvfile:
      csvwriter = csv.writer(csvfile,)
      csvwriter.writerow( [torch.cat([normalize(training_data[i][0],0.1307,0.3081) for i in range(len(training_data))]).shape]) 
    x = self.encoder(x)
    x = x.view(-1, 16 * 4 * 4)
    x = self.classifier(x)
    return x

# Return an instance of Net.
def digit_net(): return Net()
# Download training data from open datasets.
training_data_atoms = torchvision.datasets.MNIST(
    root="data",
    train=True,
    download=True,
    transform=torchvision.transforms.ToTensor(),
)

# Download test data from open datasets.
test_data_atoms = torchvision.datasets.MNIST(
    root="data",
    train=False,
    download=True,
    transform=torchvision.transforms.ToTensor(),
)

test_digits= [[] for i in range(10)]
for img, label in test_data_atoms:
    test_digits[label]+=img.float().reshape(1, 28, 28)/255
train_digits= [[] for i in range(10)]
for img, label in training_data_atoms:
    train_digits[label]+=img.float().reshape(1, 28, 28)/255

def generate_num_set(operation):
    if operation == "sum":
        n = random.randint(4,16)
        small = max(n-NUM_RANGE[1],0)
        big = min(NUM_RANGE[1],n - small)
        num1 = random.randint(small,big)
        num2 = random.randint(small,big)
        num3 = random.randint(small,big)
        return (num1,n-num1,num2,n-num2,num3,n-num3,operation)
    elif operation == "dif":
        n = random.randint(0,9)
        num1= random.randint(n,9)
        num2= random.randint(n,9)
        num3= random.randint(n,9)
        return (num1,num1-n,num2,num2-n,num3,num3-n,operation)
    elif operation == "prod":
        n = random.choice([4, 6, 8, 9, 12, 16, 18, 24, 36])
        factors = {
            4: ((2,2),(1,4)),
            6: ((2,3),(1,6)),
            8: ((4,2),(1,8)),
            9: ((3,3),(1,9)),
            12: ((2,6),(3,4)),
            16: ((2,8),(4,4)),
            18: ((2,9),(3,6)),
            24: ((3,8),(4,6)),
            36: ((4,9),(6,6)),
        }
        index_pair = random.randint(0,1)
        index_1 = random.randint(0,1)
        index_2 = random.randint(0,1)
        index_3 = random.randint(0,1)
        which = random.randint(0,1)
        num1 = factors[n][index_pair][index_1]
        num2 = factors[n][1-index_pair][index_2]
        num3 = factors[n][which][index_3]
        return (num1,int(n/num1),num2,int(n/num2),num3,int(n/num3),operation)
    elif operation == "mod":
       return "Operation not found"
    return "Operation not found"

def generate_train_data_point(numbers):
    data_point = [random.choice(train_digits[numbers[i]])[None,:,:] for i in range(5)]
    return data_point+[numbers[5]]

def generate_test_data_point(numbers):
    data_point = [random.choice(test_digits[numbers[i]])[None,:,:] for i in range(5)]
    return data_point+[numbers[5]]

training_data=[]
for i in range(1):
    operation = random.choice(["sum","dif","prod"])
    num = generate_num_set(operation)
    training_data += [generate_test_data_point(num)+[operation]]
    
test_data=[]
for i in range(1):
    operation = random.choice(["sum","dif","prod"])
    num = generate_num_set(operation)
    test_data += [generate_test_data_point(num)+[operation]]

# Normalization function to center pixel values around mu with standard deviation sigma.
def normalize(X_R, mu, sigma):
    return (X_R-mu)/sigma

# MNIST images for the train set.
def mnist_images_train(num):
    return torch.cat([normalize(training_data[i][int(num)],0.1307,0.3081) for i in range(len(training_data))])[:,None,:,:]
# MNIST images for the test set.
def mnist_images_test(num): 
    # currently num is passed as float
    return torch.cat([normalize(test_data[i][int(num)],0.1307,0.3081) for i in range(len(test_data))])[:,None,:,:]
# Observed atoms for training.
def mnist_labels_train():
    # We join the two halves (top and bottom) of MNIST and join them together to get
    # two digits side by side. The labels are atoms encoding the sum of the two digits.
    labels = [(training_data[i][-2], training_data[i][-1]) for i in range(len(training_data))]
    return [[f"last_num({num})",f"equal("+ op +")"] for num,op in labels]

# keep labels for test data
import csv
def note_label_for_test(test_data):
  with open("operation_label.csv",'w',newline = '') as csvfile:
    csvwriter = csv.writer(csvfile)
    for i in range(len(test_data)):
      csvwriter.writerow([test_data[i][-2],test_data[i][-1]]) 
note_label_for_test(test_data)

#end.

% Data of the first digit.
input(0) ~ test(@mnist_images_test(0)), train(@mnist_images_train(0)).
% Data of the second digit.
input(1) ~ test(@mnist_images_test(1)), train(@mnist_images_train(1)).
% Data of the third digit.
input(2) ~ test(@mnist_images_test(2)), train(@mnist_images_train(2)).
% Data of the fourth digit.
input(3) ~ test(@mnist_images_test(3)), train(@mnist_images_train(3)).
% Data of the fifth digit.
input(4) ~ test(@mnist_images_test(4)), train(@mnist_images_train(4)).

% Neural annotated disjunction over each digit from 0 to 9; use Adam as optimizer
% and a learning rate of 0.001.
?::digit(X, {0..9}) as @digit_net with optim = "Adam", lr = 0.001 :- input(X).
% The sum.

sum1(X) :- digit(0, A), digit(1, B), X = A+B.
sum2(Y) :- digit(2, A), digit(3, B), Y = A+B.
equal(sum) :- sum1(X),sum2(Y),X=Y.

dif1(X) :- digit(0, A), digit(1, B), X = A-B.
dif2(Y) :- digit(2, A), digit(3, B), Y = A-B.
equal(dif):- dif1(X),dif2(Y),X=Y.

prod1(X) :- digit(0, A), digit(1, B), X = A*B.
prod2(Y) :- digit(2, A), digit(3, B), Y = A*B.
equal(prod) :- prod1(X), prod2(Y), X=Y.

last_num(L):- digit(4,A),equal_sum,sum1(X),L=X-A.
last_num(L):- digit(4,A),equal_dif,dif1(X),L=A-X.
last_num(L):- digit(4,A),equal_prod,prod1(X),X\A=0, L = X/A.

sat :- equal(sum).
sat :- equal(dif).
sat :- equal(prod).

% Learn the parameters of the program from the "sum(X)" atoms.
#learn @mnist_labels_train, lr = 1., niters = 5, alg = "lagrange", batch = 50.
#semantics maxent.
% Ask for the probability of all groundings of last_num(L).
#query last_num(L)|sat.
